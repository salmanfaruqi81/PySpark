{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edcefa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c300b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName('PySparkLogisticRegression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fa2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv('diabetes.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c306270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021bf861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- BloodPressure: string (nullable = true)\n",
      " |-- SkinThickness: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema() # All values are in string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96040d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "new_data = dataset.select(*(col(c).cast('float').alias(c) for c in dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b23a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- Glucose: float (nullable = true)\n",
      " |-- BloodPressure: float (nullable = true)\n",
      " |-- SkinThickness: float (nullable = true)\n",
      " |-- Insulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Outcome: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()# All values converted from String to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80304646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|          0|      0|            0|            0|      0|  0|                       0|  0|      0|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, col, isnan, when\n",
    "\n",
    "new_data.select([count(when(col(c).isNull(), c)).alias(c) for c in new_data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a954",
   "metadata": {},
   "source": [
    "No Null Values to deal with Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "904615ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = new_data.columns\n",
    "cols.remove(\"Outcome\")\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2addd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+-------+\n",
      "|features                                                               |Outcome|\n",
      "+-----------------------------------------------------------------------+-------+\n",
      "|[6.0,148.0,72.0,35.0,0.0,33.599998474121094,0.6269999742507935,50.0]   |1.0    |\n",
      "|[1.0,85.0,66.0,29.0,0.0,26.600000381469727,0.35100001096725464,31.0]   |0.0    |\n",
      "|[8.0,183.0,64.0,0.0,0.0,23.299999237060547,0.671999990940094,32.0]     |1.0    |\n",
      "|[1.0,89.0,66.0,23.0,94.0,28.100000381469727,0.16699999570846558,21.0]  |0.0    |\n",
      "|[0.0,137.0,40.0,35.0,168.0,43.099998474121094,2.2880001068115234,33.0] |1.0    |\n",
      "|[5.0,116.0,74.0,0.0,0.0,25.600000381469727,0.20100000500679016,30.0]   |0.0    |\n",
      "|[3.0,78.0,50.0,32.0,88.0,31.0,0.24799999594688416,26.0]                |1.0    |\n",
      "|[10.0,115.0,0.0,0.0,0.0,35.29999923706055,0.1340000033378601,29.0]     |0.0    |\n",
      "|[2.0,197.0,70.0,45.0,543.0,30.5,0.15800000727176666,53.0]              |1.0    |\n",
      "|[8.0,125.0,96.0,0.0,0.0,0.0,0.23199999332427979,54.0]                  |1.0    |\n",
      "|[4.0,110.0,92.0,0.0,0.0,37.599998474121094,0.19099999964237213,30.0]   |0.0    |\n",
      "|[10.0,168.0,74.0,0.0,0.0,38.0,0.5370000004768372,34.0]                 |1.0    |\n",
      "|[10.0,139.0,80.0,0.0,0.0,27.100000381469727,1.440999984741211,57.0]    |0.0    |\n",
      "|[1.0,189.0,60.0,23.0,846.0,30.100000381469727,0.39800000190734863,59.0]|1.0    |\n",
      "|[5.0,166.0,72.0,19.0,175.0,25.799999237060547,0.5870000123977661,51.0] |1.0    |\n",
      "|[7.0,100.0,0.0,0.0,0.0,30.0,0.48399999737739563,32.0]                  |1.0    |\n",
      "|[0.0,118.0,84.0,47.0,230.0,45.79999923706055,0.5509999990463257,31.0]  |1.0    |\n",
      "|[7.0,107.0,74.0,0.0,0.0,29.600000381469727,0.2540000081062317,31.0]    |1.0    |\n",
      "|[1.0,103.0,30.0,38.0,83.0,43.29999923706055,0.18299999833106995,33.0]  |0.0    |\n",
      "|[1.0,115.0,70.0,30.0,96.0,34.599998474121094,0.5289999842643738,32.0]  |1.0    |\n",
      "+-----------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transforming the Dataset:\n",
    "\n",
    "data = assembler.transform(new_data)\n",
    "data.select('features', 'Outcome').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd692216",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler = StandardScaler().setInputCol('features').setOutputCol('Scaled_features')\n",
    "data = standardscaler.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff10664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     Scaled_features|Outcome|\n",
      "+--------------------+-------+\n",
      "|[1.78063837321943...|    1.0|\n",
      "|[0.29677306220323...|    0.0|\n",
      "|[2.37418449762590...|    1.0|\n",
      "|[0.29677306220323...|    0.0|\n",
      "|[0.0,4.2849165233...|    1.0|\n",
      "|[1.48386531101619...|    0.0|\n",
      "|[0.89031918660971...|    1.0|\n",
      "|[2.96773062203238...|    0.0|\n",
      "|[0.59354612440647...|    1.0|\n",
      "|[2.37418449762590...|    1.0|\n",
      "|[1.18709224881295...|    0.0|\n",
      "|[2.96773062203238...|    1.0|\n",
      "|[2.96773062203238...|    0.0|\n",
      "|[0.29677306220323...|    1.0|\n",
      "|[1.48386531101619...|    1.0|\n",
      "|[2.07741143542266...|    1.0|\n",
      "|[0.0,3.6906580274...|    1.0|\n",
      "|[2.07741143542266...|    1.0|\n",
      "|[0.29677306220323...|    0.0|\n",
      "|[0.29677306220323...|    1.0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled_data = data.select('Scaled_features', 'Outcome')\n",
    "assembled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdd99b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and testing data 70:30\n",
    "\n",
    "train, test = assembled_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d51f6e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Scaled_features: vector, Outcome: float]\n",
      "DataFrame[Scaled_features: vector, Outcome: float]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9163afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(labelCol='Outcome', featuresCol='Scaled_features', maxIter=10)\n",
    "model = log_reg.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "322b7579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_49b97e75ac8f, numClasses=2, numFeatures=8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ea54f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Outcome|prediction|\n",
      "+-------+----------+\n",
      "|    0.0|       0.0|\n",
      "|    1.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    1.0|       0.0|\n",
      "|    1.0|       1.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model.transform(test)\n",
    "prediction_test.select(\"Outcome\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "437969bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing row scores on the test set:\n",
    "\n",
    "predictionAndLabels = prediction_test.select('Outcome', 'prediction').rdd.map(lambda row: row[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28bdcf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Salman\\spark-3.2.1-bin-hadoop3.2\\python\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b55d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7625902992776058\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d681e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2e26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
